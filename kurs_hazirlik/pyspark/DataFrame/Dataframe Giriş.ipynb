{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aşağıdaki ayarları bilgisayarınızın belleğine göre değiştirebilirsiniz\n",
    "spark = SparkSession.builder \\\n",
    ".master(\"local[4]\") \\\n",
    ".appName(\"Dataset-Olusturmak\") \\\n",
    ".config(\"spark.executor.memory\",\"4g\") \\\n",
    ".config(\"spark.driver.memory\",\"2g\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "# sparkContext'i kısaltmada tut\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# listeden dataframe oluşturmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "list_rdd = sc.parallelize([1,2,3,4,5,6,4,5]).map(lambda x: Row(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sütun ismi bir tane bile olsa Python listesi olarak parametre verilir\n",
    "df_from_list = list_rdd.toDF(['rakamlar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rakamlar=1),\n",
       " Row(rakamlar=2),\n",
       " Row(rakamlar=3),\n",
       " Row(rakamlar=4),\n",
       " Row(rakamlar=5),\n",
       " Row(rakamlar=6),\n",
       " Row(rakamlar=4),\n",
       " Row(rakamlar=5)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_list.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# range ile dataframe yaratmak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yöntem-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_range = sc.parallelize(range(10,100,5)). \\\n",
    "map(lambda x: (x,)). \\\n",
    "toDF([\"range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(range=10), Row(range=15), Row(range=20)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_range.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yöntem-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df_from_range2 =spark.createDataFrame(range(10,100,5), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value=10), Row(value=15), Row(value=20)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_range2.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dosyadan veri okuyarak Dataframe oluşturmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_file = spark.read.csv(\"D:\\\\Datasets\\\\OnlineRetail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='InvoiceNo;StockCode;Description;Quantity;InvoiceDate;UnitPrice;CustomerID;Country'),\n",
       " Row(_c0='536365;85123A;WHITE HANGING HEART T-LIGHT HOLDER;6;1.12.2010 08:26;2'),\n",
       " Row(_c0='536365;71053;WHITE METAL LANTERN;6;1.12.2010 08:26;3')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_file.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_file = spark.read. \\\n",
    "option(\"sep\",\";\"). \\\n",
    "csv(\"D:\\\\Datasets\\\\OnlineRetail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='InvoiceNo', _c1='StockCode', _c2='Description', _c3='Quantity', _c4='InvoiceDate', _c5='UnitPrice', _c6='CustomerID', _c7='Country'),\n",
       " Row(_c0='536365', _c1='85123A', _c2='WHITE HANGING HEART T-LIGHT HOLDER', _c3='6', _c4='1.12.2010 08:26', _c5='2,55', _c6='17850', _c7='United Kingdom'),\n",
       " Row(_c0='536365', _c1='71053', _c2='WHITE METAL LANTERN', _c3='6', _c4='1.12.2010 08:26', _c5='3,39', _c6='17850', _c7='United Kingdom')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_file.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_from_file.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_file = spark.read. \\\n",
    "option(\"sep\",\";\"). \\\n",
    "option(\"header\",\"True\"). \\\n",
    "option(\"inferSchema\",\"True\"). \\\n",
    "csv(\"D:\\\\Datasets\\\\OnlineRetail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2,55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2,75|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_from_file.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_from_file.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [Quantity#86 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(Quantity#86 ASC NULLS FIRST, 200)\n",
      "   +- *(1) FileScan csv [InvoiceNo#83,StockCode#84,Description#85,Quantity#86,InvoiceDate#87,UnitPrice#88,CustomerID#89,Country#90] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/D:/Datasets/OnlineRetail.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<InvoiceNo:string,StockCode:string,Description:string,Quantity:int,InvoiceDate:string,UnitP...\n"
     ]
    }
   ],
   "source": [
    "df_from_file.sort(\"Quantity\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dinamik conf ayarı ve shuffle partition sayısını değiştirme\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [Quantity#86 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(Quantity#86 ASC NULLS FIRST, 5)\n",
      "   +- *(1) FileScan csv [Description#85,Quantity#86] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/D:/Datasets/OnlineRetail.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Description:string,Quantity:int>\n"
     ]
    }
   ],
   "source": [
    "# Yeni conf ile sort\n",
    "df_from_file.select(\"Description\",\"Quantity\").sort(\"Quantity\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [Quantity#86 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(Quantity#86 ASC NULLS FIRST, 5)\n",
      "   +- *(1) FileScan csv [Description#85,Quantity#86] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/D:/Datasets/OnlineRetail.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Description:string,Quantity:int>\n"
     ]
    }
   ],
   "source": [
    "# Dinamik conf ayarı ve shuffle partition sayısını değiştirme\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",\"5\")\n",
    "# Yeni conf ile sort\n",
    "df_from_file.select(\"Description\",\"Quantity\").sort(\"Quantity\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
